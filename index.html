<!DOCTYPE html>
<html>
  <head>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <link rel="stylesheet" href="styles.css">
  </head>
  <body>
    <div id="container">
      <div id="image-container">
        <img src="https://drive.google.com/uc?export=view&id=1BxvqND0MeF8Z-dPpYBvKuV-SQdx6fBrF" alt="AutoAssistant Image">
      </div>

      <div id="input-container">
        <div id="name-date-container">
          <div id="name-container">
            <label for="name">Your Name:</label>
            <input id="name" name="name" type="text" value="MedX User" placeholder="your name here" />
          </div>
          <div id="date-container">
            <span id="date-label">Date: </span>
            <span id="current-date"></span>
          </div>
        </div>
      </div>

      <div id="conversation-container">
        <div id="conversation-box">
          <ul id="root"></ul>
        </div>
      </div>

      <div id="message-container">
        <label for="name">Message:</label>
        <div id="message-input-container">
          <input id="user-input" name="user-input" type="text" placeholder="Enter your response..." />
          <button id="send" type="button">Send</button>
          <button id="voice-input" type="button"><i class="fa fa-microphone"></i> Speak</button>
        </div>
      </div>
    </div>

    <ul id="root"></ul>

    <script defer>
      const API_KEY = "VF.DM.648c97994eb8a700073a3fa9.Nrhwtr0L4cS9MaT3"; // it should look like this: VF.DM.XXXXXXX.XXXXXX... keep this a secret!

      let recognition;

      // Check if browser supports speech recognition
      if ('webkitSpeechRecognition' in window) {
        recognition = new webkitSpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;

        recognition.onresult = function (event) {
          const userInput = event.results[0][0].transcript;
          $("#root").append(`<li> > ${userInput}</li>`);
          // Call an Interaction Method to advance the conversation based on `userInput`.
          interact({ type: 'text', payload: userInput });
        };

        // Start listening for user input
        function startListening() {
          recognition.start();
        }

        // Click handler - This advances the conversation session
        async function handleSend() {
          const userInput = $("#user-input").val();
          $("#root").append(`<li> > ${userInput}</li>`);
          // clear the input field
          $("#user-input").val('');

          // Call an Interaction Method to advance the conversation based on `userInput`.
          interact({ type: 'text', payload: userInput });
        }

        // Register the click handler on the send button
        $("#send").on("click", handleSend);

        // Register the click handler on the voice input button
        $("#voice-input").on("click", startListening);
      } else {
        alert('Speech recognition not supported in this browser. Please use a compatible browser for voice chat functionality.');
      }

      const interact = (request) =>
        // call the voiceflow api with the user's name & request, get back a response
        fetch(`https://general-runtime.voiceflow.com/state/user/${encodeURI($("#name").val())}/interact`, {
          method: 'POST',
          headers: { Authorization: API_KEY, 'Content-Type': 'application/json' },
          body: JSON.stringify({ request }),
        })
          .then((res) => res.json())
          .then((trace) => {
            console.log("API RESPONSE BODY:", trace);
            trace.forEach((trace) => {
              if (trace.type === 'speak' || trace.type === 'text') {
                const message = trace.payload.message;
                $("#root").append(`<li>${message}</li>`);
                // Speak the message
                speakText(message).then(() => {
                  // Prompt the next question after speaking
                  if (trace.type === 'text') {
                    const nextQuestion = trace.payload.message;
                    // Call an Interaction Method to advance the conversation
                    interact({ type: 'text', payload: nextQuestion });
                  }
                });
              } else if (trace.type === 'end') {
                $("#root").append(`<li><b>The End!</b></li>`);
              }
            });
          });

      // Call an Interaction Method to start the conversation
      interact({ type: 'launch' });

      // Function to speak the given text
      function speakText(text) {
        return new Promise((resolve, reject) => {
          const utterance = new SpeechSynthesisUtterance(text);
          utterance.onend = resolve;
          utterance.onerror = reject;
          speechSynthesis.speak(utterance);
        });
      }
    </script>
  </body>
</html>
